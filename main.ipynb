{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tabulate #가독성 print\n",
    "#!pip install -q mediapipe==0.10.0\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#densenet model setting\n",
    "import torchvision.models as models\n",
    "from torchvision.models import densenet, DenseNet121_Weights\n",
    "#Resnet model setting\n",
    "from torchvision.models import resnet\n",
    "#ConfusionMatrixDisplay로 표현하기 위해 사이킷런 import\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import torchvision.models\n",
    "#pose standard module\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import seaborn as sns  #시각화 \n",
    "import mediapipe as mp\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#CNN visualization module\n",
    "from PIL import Image\n",
    "#angle module\n",
    "import math\n",
    "#Regression model import\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data naming change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/' \n",
    "logdir_path = os.path.normpath('result')\n",
    "if os.path.exists(logdir_path) == False:\n",
    "  os.mkdir(logdir_path)\n",
    "  \n",
    "#이름바꾸기 형식에 맞게 \n",
    "def rename(data_root):\n",
    "  tmp = glob(data_root+\"*/*.jpg\")\n",
    "  for i in tmp:\n",
    "    string = \"\"\n",
    "    tmp_li = (i.split('/')[-1].split('-'))\n",
    "    string = tmp_li[0] + '_' + tmp_li[1]\n",
    "    #print(string)\n",
    "    #print(i)\n",
    "    #### 데이터 더 많이 넣어서 해보기 !!!!\n",
    "    #print(data_path = i.split('/'))\n",
    "    #os.rename(i, data_path + string)\n",
    "\n",
    "#여러 확장자를 jpg로 형식바꾸기 \n",
    "def any2jpg(data_root):\n",
    "  tmp = glob(data_root+\"*/\"+\"*/*\")\n",
    "  #print(tmp)\n",
    "  for img in tmp:\n",
    "    protocol = (img.split('.')[-1])\n",
    "    if protocol != 'jpg':\n",
    "      #print(img)\n",
    "      rename = img.split(protocol)[0] + \"jpg\"\n",
    "      #print(rename)\n",
    "      os.rename(img, rename)\n",
    "#any2jpg(data_root)\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data mask preprocessing with bidirect filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "image_li = []\n",
    "df = pd.DataFrame()\n",
    "pj_path = 'mp'\n",
    "save_PATH = os.path.join('data','mask')\n",
    "dataset = glob('data/test/*/*') + glob('data/train/*/*') + glob('data/valid/*/*')\n",
    "print(type(dataset))\n",
    "print(f\"dataset 개수 : {len(dataset)}\")\n",
    "###########setting############\n",
    "contrast = 0.8\n",
    "brightness = 1\n",
    "\n",
    "###########\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    static_image_mode = True,\n",
    "    enable_segmentation=True,\n",
    ") as pose:\n",
    "    for data in dataset:\n",
    "        #배경 제거\n",
    "        image = cv2.imread(data)\n",
    "        image_li.append(image)\n",
    "        ## 대조 밝기 변경 : 특정 데이터들떄문\n",
    "        image = cv2.convertScaleAbs(image, alpha = contrast, beta = brightness)\n",
    "        h, w, _ = image.shape\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        annotated_image = image.copy()\n",
    "        #사람만 추출\n",
    "        ### 공동 양방향 필터사용 * https://learn.foundry.com/ko/nuke/content/comp_environment/filters/bilateral.html\n",
    "        condition = np.stack((results.segmentation_mask,) * 3, axis = -1) \n",
    "        bg_image = np.zeros(image.shape, dtype = np.uint8)\n",
    "        bg_image[:] = (192,192,192) #배경 회색으로 처리       \n",
    "        annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "        x = []\n",
    "        #image.flags.writeable = False\n",
    "        #print(data)\n",
    "        \n",
    "        data_path = os.path.join(save_PATH, data.split('/')[-3],data.split('/')[-2],data.split('/')[-1])\n",
    "        cv2.imwrite(data_path, annotated_image)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 개수 확인\n",
    "train_O_len = len(os.listdir('data/train/O/'))\n",
    "train_X_len = len(os.listdir('data/train/X/'))\n",
    "valid_O_len = len(os.listdir('data/valid/O'))\n",
    "valid_X_len = len(os.listdir('data/valid/X'))\n",
    "test_O_len = len(os.listdir('data/test/O/'))\n",
    "test_X_len = len(os.listdir('data/test/X/'))\n",
    "print(\"---------------Train------------\")\n",
    "print(train_O_len)\n",
    "print(train_X_len)\n",
    "print(\"---------------VALID------------\")\n",
    "print(len(os.listdir('data/valid/O')))\n",
    "print(len(os.listdir('data/valid/X')))\n",
    "print(\"---------------Test------------\")\n",
    "print(test_O_len)\n",
    "print(test_X_len)\n",
    "print('---------------TOTAL------------')\n",
    "print(train_O_len+train_X_len+valid_O_len+valid_X_len+test_O_len+test_X_len)\n",
    "#데이터 shpae 알아보기\n",
    "root = glob('./data/*/*/*')\n",
    "root\n",
    "for i in root:\n",
    "  img = cv2.imread(os.path.join(i))\n",
    "  #print(img.shape)\n",
    "  break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transform\n",
    "train_transforms = transforms.Compose(\n",
    "  [\n",
    "    transforms.RandomRotation(degrees=(0,15)),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(5, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor()\n",
    "  ]\n",
    ")\n",
    "valid_transforms = transforms.Compose(\n",
    "  [\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "  ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "  [\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "  ]\n",
    ")\n",
    "train_batch_size = 6\n",
    "valid_batch_size = 4\n",
    "\n",
    "#prefix setting \n",
    "train_path = 'data/train/'\n",
    "valid_path = 'data/valid/'\n",
    "test_path = 'data/test/'\n",
    "\n",
    "#data check \n",
    "check_trainset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
    "check_trainloader = torch.utils.data.DataLoader(check_trainset, batch_size = train_batch_size, shuffle = True)\n",
    "check_validset = torchvision.datasets.ImageFolder(root = valid_path, transform = valid_transforms)\n",
    "check_validloader = torch.utils.data.DataLoader(check_validset, batch_size = valid_batch_size, shuffle = True)\n",
    "testset = torchvision.datasets.ImageFolder(root = test_path, transform = test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = test_O_len+test_X_len, shuffle = False)\n",
    "#data check\n",
    "for X, y in check_trainloader:\n",
    "  print(X.shape, y.shape)\n",
    "  f = X[0][0].numpy()\n",
    "  plt.imshow(f, cmap='gray')\n",
    "  plt.show()\n",
    "  break\n",
    "  \n",
    "for X, y in check_validloader:\n",
    "  print(X.shape, y.shape)\n",
    "  f = X[0][0].numpy()\n",
    "  plt.figure()\n",
    "  plt.imshow(f, cmap='gray')\n",
    "  plt.show()\n",
    "  break\n",
    "  \n",
    "for X, y in testloader:\n",
    "  print(X.shape, y.shape)\n",
    "  f = X[0][0].numpy()\n",
    "  plt.figure()\n",
    "  plt.imshow(f, cmap='gray')\n",
    "  plt.show()\n",
    "  break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model 검증(densenet , resnet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet.DenseNet()\n",
    "model.features.conv0 = torch.nn.Conv2d(in_channels= 3,  out_channels=64, kernel_size=7)\n",
    "model.classifier = torch.nn.Linear(in_features= 1024, out_features= 2, bias= True)\n",
    "#loss, accuracy plot\n",
    "target_cls =check_trainset.classes \n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### denset training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result check\n",
    "loss_train = np.array([])\n",
    "accs_train = np.array([])\n",
    "accs_valid = np.array([])\n",
    "\n",
    "#data load\n",
    "trainset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
    "validset = torchvision.datasets.ImageFolder(root = valid_path, transform = valid_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch_size, shuffle = True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size = valid_batch_size, shuffle = True)\n",
    "#hyper parma setting\n",
    "lr = 42e-4\n",
    "num_epochs = 500\n",
    "# loss, algo\n",
    "loss =torch.nn.CrossEntropyLoss() #CE Loss\n",
    "alg = torch.optim.Adam(model.parameters(), lr = lr) #adam\n",
    "for epoch in range(num_epochs):\n",
    "    i=0\n",
    "    l_epoch = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for X,y in trainloader:\n",
    "        i=i+1\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        y_hat=model(X)\n",
    "        correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "        l=loss(y_hat,y)\n",
    "        l_epoch+=l\n",
    "        alg.zero_grad()\n",
    "        l.backward()\n",
    "        alg.step()\n",
    "\n",
    "    loss_train = np.append(loss_train,l_epoch.cpu().detach().numpy()/i)\n",
    "    accs_train = np.append(accs_train,correct.cpu()/len(trainset))\n",
    "\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for X,y in validloader:\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        y_hat = model(X)\n",
    "        correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "\n",
    "    accs_valid = np.append(accs_valid,correct.cpu()/len(validset))\n",
    "\n",
    "\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        print('epoch: %d '%(epoch))\n",
    "        print('train loss: ',loss_train[-1])\n",
    "        print('train accuracy: ',accs_train[-1])\n",
    "        print('valid accuracy: ',accs_valid[-1])\n",
    "        plt.figure(2,dpi=80)\n",
    "        plt.subplot(121)\n",
    "        plt.plot(loss_train,label='train loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(accs_train,label='train accuracy')\n",
    "        plt.plot(accs_valid,label='valid accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.title('epoch: %d '%(epoch))\n",
    "        plt.savefig('result/cnn_model/densenet/Densenet_loss.png')\n",
    "        #plt.show()\n",
    "        plt.close(2)\n",
    "        #model save\n",
    "\n",
    "    if accs_valid[-1] >= 0.98 and accs_train[-1] >= 0.98 :\n",
    "        torch.save(   \n",
    "            model.state_dict(), os.path.join( f\"./model/final_densenet.pth\")\n",
    "        )\n",
    "        break\n",
    "\n",
    "# loss check\n",
    "plt.figure(2,dpi=80)\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_train,label='train loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(122)\n",
    "plt.plot(accs_train,label='train accuracy')\n",
    "plt.plot(accs_valid,label='valid accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('./model/loss/densenet_loss.jpg')\n",
    "plt.show()\n",
    "\n",
    "N = 0\n",
    "I = Image.open(validset.imgs[N][0])\n",
    "X = train_transforms(I)\n",
    "y = validset.targets[N]\n",
    "\n",
    "print(target_cls[y])\n",
    "y_hat = model(X.unsqueeze(0).to(device))\n",
    "print(y_hat.cpu().detach().numpy())\n",
    "y_hat = y_hat.argmax(dim=1)\n",
    "print(f'prediction of model: {target_cls[y_hat.cpu().numpy()[0]]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### denset model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary validation set\n",
    "y_list = np.array([])\n",
    "y_hat_list = np.array([])\n",
    "for X,y in testloader:\n",
    "  y_hat = model(X.to(device))    \n",
    "  y_hat = y_hat.argmax(dim=1)\n",
    "  y_list = np.append(y_list,y)\n",
    "  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())\n",
    "\n",
    "#print(len(y_hat_list))\n",
    "\n",
    "print(classification_report(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    target_names=target_cls))\n",
    "\n",
    "#summary confusion matrix \n",
    "cm = confusion_matrix(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    #normalize='true',\n",
    ")\n",
    "\n",
    "#ConfusionMatirxDisplay(confusion_matrx = {confusion_matrix var}, display_labels = {결과 class})\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=target_cls,\n",
    ")\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])\n",
    "\n",
    "total= test_O_len+test_X_len\n",
    "###valid accuracy 측정 \n",
    "TT = cm[0][0] + cm[1][1]\n",
    "test_prediction = 100 * (TT / total)\n",
    "print(f\"test data 총 {total}명 중 맞춘 확률 : {test_prediction}%\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. resnet "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = torchvision.models.resnet101()\n",
    "resnet_model.fc = torch.nn.Linear(in_features =2048, out_features=2, bias = True)\n",
    "print(resnet_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper param, loss, alg 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet_model.to(device)\n",
    "\n",
    "#hyper parma setting\n",
    "lr = 42e-4\n",
    "num_epochs = 500\n",
    "# loss, algo\n",
    "loss =torch.nn.CrossEntropyLoss() #CE Loss\n",
    "alg = torch.optim.Adam(resnet_model.parameters(), lr = lr) #adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result check\n",
    "loss_train = np.array([])\n",
    "accs_train = np.array([])\n",
    "accs_valid = np.array([])\n",
    "\n",
    "#data load\n",
    "trainset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
    "validset = torchvision.datasets.ImageFolder(root = valid_path, transform = valid_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch_size, shuffle = True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size = valid_batch_size, shuffle = True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    i=0\n",
    "    l_epoch = 0\n",
    "    correct = 0\n",
    "    resnet_model.train()\n",
    "    for X,y in trainloader:\n",
    "        i=i+1\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        y_hat=resnet_model(X)\n",
    "        correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "        l=loss(y_hat,y)\n",
    "        l_epoch+=l\n",
    "        alg.zero_grad()\n",
    "        l.backward()\n",
    "        alg.step()\n",
    "\n",
    "    loss_train = np.append(loss_train,l_epoch.cpu().detach().numpy()/i)\n",
    "    accs_train = np.append(accs_train,correct.cpu()/len(trainset))\n",
    "\n",
    "    correct = 0\n",
    "    resnet_model.eval()\n",
    "    for X,y in validloader:\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        y_hat = resnet_model(X)\n",
    "        correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "\n",
    "    accs_valid = np.append(accs_valid,correct.cpu()/len(validset))\n",
    "\n",
    "\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        print('epoch: %d '%(epoch))\n",
    "        print('train loss: ',loss_train[-1])\n",
    "        print('train accuracy: ',accs_train[-1])\n",
    "        print('valid accuracy: ',accs_valid[-1])\n",
    "        plt.figure(2,dpi=80)\n",
    "        plt.subplot(121)\n",
    "        plt.plot(loss_train,label='train loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(accs_train,label='train accuracy')\n",
    "        plt.plot(accs_valid,label='valid accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.title('epoch: %d '%(epoch))\n",
    "        plt.savefig('./result/cnn_model/resnet_loss_curve.png')\n",
    "        #plt.show()\n",
    "        plt.close(2)\n",
    "        \n",
    "#resnet_model save        \n",
    "    if accs_valid[-1] >= 0.98 and accs_train[-1] >= 0.98 :\n",
    "        torch.save(   \n",
    "            resnet_model.state_dict(), os.path.join( f\"./result/final_resnet.pth\")\n",
    "        )\n",
    "        break\n",
    "\n",
    "\n",
    "#loss, accuracy plot\n",
    "target_cls =trainset.classes \n",
    "target_cls\n",
    "\n",
    "#result check\n",
    "plt.figure(2,dpi=80)\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_train,label='train loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(122)\n",
    "plt.plot(accs_train,label='train accuracy')\n",
    "plt.plot(accs_valid,label='valid accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('./model/loss/resnet_loss.jpg')\n",
    "plt.show()\n",
    "\n",
    "N = 0\n",
    "I = Image.open(validset.imgs[N][0])\n",
    "X = train_transforms(I)\n",
    "y = validset.targets[N]\n",
    "\n",
    "#print(target_cls[y])\n",
    "y_hat = resnet_model(X.unsqueeze(0).to(device))\n",
    "#print(y_hat.cpu().detach().numpy())\n",
    "y_hat = y_hat.argmax(dim=1)\n",
    "print(f'prediction of resnet_model: {target_cls[y_hat.cpu().numpy()[0]]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary validation set\n",
    "y_list = np.array([])\n",
    "y_hat_list = np.array([])\n",
    "resnet_model.eval()\n",
    "for X,y in testloader:\n",
    "  y_hat = resnet_model(X.to(device))    \n",
    "  y_hat = y_hat.argmax(dim=1)\n",
    "  y_list = np.append(y_list,y)\n",
    "  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())\n",
    "\n",
    "#print(len(y_hat_list))\n",
    "\n",
    "print(classification_report(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    target_names=target_cls))\n",
    "\n",
    "#summary confusion matrix \n",
    "cm = confusion_matrix(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    #normalize='true',\n",
    ")\n",
    "\n",
    "#ConfusionMatirxDisplay(confusion_matrx = {confusion_matrix var}, display_labels = {결과 class})\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=target_cls,\n",
    ")\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])\n",
    "\n",
    "total= test_O_len+test_X_len\n",
    "###valid accuracy 측정 \n",
    "TT = cm[0][0] + cm[1][1]\n",
    "test_prediction = 100 * (TT / total)\n",
    "print(f\"test data 총 {total}명 중 맞춘 확률 : {test_prediction}%\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing densenet & resnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. densenet testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 저장한 모델.pth 를 지정해줘야함\n",
    "test_model_name = './model/final_densenet.pth'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#model load\n",
    "test_model = densenet.DenseNet()\n",
    "test_model.features.conv0 = torch.nn.Conv2d(in_channels= 3,  out_channels=64, kernel_size=7)\n",
    "test_model.classifier = torch.nn.Linear(in_features= 1024, out_features= 2, bias= True)\n",
    "test_model.load_state_dict(torch.load(os.path.join(test_model_name)))\n",
    "print(test_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary validation set\n",
    "y_list = np.array([])\n",
    "y_hat_list = np.array([])\n",
    "\n",
    "for X,y in testloader:\n",
    "  y_hat = test_model(X)    \n",
    "  y_hat = y_hat.argmax(dim=1)\n",
    "  y_list = np.append(y_list,y)\n",
    "  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())\n",
    "\n",
    "#print(len(y_hat_list))\n",
    "#ConfusionMatrixDisplay로 표현하기 위해 사이킷런 import\n",
    "#print(classification_report(\n",
    "#    y_list,\n",
    "#    y_hat_list,\n",
    "#    target_names=target_cls))\n",
    "\n",
    "print(classification_report(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    target_names=target_cls))\n",
    "\n",
    "#summary confusion matrix \n",
    "#cm = confusion_matrix(\n",
    "#    y_list,\n",
    "#    y_hat_list,\n",
    "#    #normalize='true',\n",
    "#)\n",
    "\n",
    "\n",
    "#ConfusionMatirxDisplay(confusion_matrx = {confusion_matrix var}, display_labels = {결과 class})\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=target_cls,\n",
    ")\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])\n",
    "\n",
    "total= test_X_len+test_O_len\n",
    "###valid accuracy 측정 \n",
    "TT = cm[0][0] + cm[1][1]\n",
    "test_prediction = 100 * (TT / total)\n",
    "print(f\"test data 총 {total}명 중 맞춘 확률 : {test_prediction}%\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. resnet testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 저장한 모델.pth 를 지정해줘야함\n",
    "test_model_name = './model/final_resnet.pth'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#model load\n",
    "resnet_model = torchvision.models.resnet101()\n",
    "resnet_model.fc = torch.nn.Linear(in_features =2048, out_features=2, bias = True)\n",
    "resnet_model.load_state_dict(torch.load(test_model_name).features)\n",
    "print(resnet_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary validation set\n",
    "y_list = np.array([])\n",
    "y_hat_list = np.array([])\n",
    "\n",
    "for X,y in testloader:\n",
    "  y_hat = test_model(X)    \n",
    "  y_hat = y_hat.argmax(dim=1)\n",
    "  y_list = np.append(y_list,y)\n",
    "  y_hat_list = np.append(y_hat_list,y_hat.cpu().numpy())\n",
    "\n",
    "#print(len(y_hat_list))\n",
    "#ConfusionMatrixDisplay로 표현하기 위해 사이킷런 import\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "#print(classification_report(\n",
    "#    y_list,\n",
    "#    y_hat_list,\n",
    "#    target_names=target_cls))\n",
    "\n",
    "#summary confusion matrix \n",
    "cm = confusion_matrix(\n",
    "    y_list,\n",
    "    y_hat_list,\n",
    "    #normalize='true',\n",
    ")\n",
    "\n",
    "\n",
    "#ConfusionMatirxDisplay(confusion_matrx = {confusion_matrix var}, display_labels = {결과 class})\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=target_cls,\n",
    ")\n",
    "disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1])\n",
    "\n",
    "total= test_O_len + test_X_len\n",
    "###valid accuracy 측정 \n",
    "TT = cm[0][0] + cm[1][1]\n",
    "test_prediction = 100 * (TT / total)\n",
    "print(f\"test data 총 {total}명 중 맞춘 확률 : {test_prediction}%\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose dot detector (33 부위) train\n",
    "CNN 모델이 저렇게 정한 이유에 대해 알아보기 위해 임의의 기준(5가지)를 정하여 기준값에 대한 angle 확인하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각도 계산기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calculator:\n",
    "  def __init__(self, array, width, height):\n",
    "    x1 = 0\n",
    "    x2 = 0\n",
    "    x3 = 0\n",
    "    y1 = 0\n",
    "    y2 = 0\n",
    "    y3 = 0\n",
    "    self.array = array\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "  def angle1(self):\n",
    "    self.x1, self.y1 = self.array[12]\n",
    "    self.x2, self.y2 = self.array[14]\n",
    "    self.x3, self.y3 = [self.array[12][0],self.height]\n",
    "    \n",
    "    try:\n",
    "      a1 = (self.y2 - self.y1) / (self.x2 - self.x1)\n",
    "    except ZeroDivisionError:\n",
    "      a1 = (self.y2 - self.y1) / 1\n",
    "    try:\n",
    "      a3 = (self.y3 - self.y2) / (self.x3 - self.x2)\n",
    "    except ZeroDivisionError:\n",
    "      a3 = (self.y3 - self.y2) / 1\n",
    "      \n",
    "    angle_rad1 = math.atan(abs((a1 - a3) / (1 + a1 * a3)))\n",
    "    angle1 = math.degrees(angle_rad1)\n",
    "    angle_rad2 = math.atan(abs((a3)))\n",
    "    angle2 = 90 - math.degrees(angle_rad2)\n",
    "    #print(angle1, angle2)\n",
    "    std= 180 - angle1 - angle2\n",
    "    if std > 0 and std <90:\n",
    "      std = 180 - std\n",
    "    return  std\n",
    "  def angle2(self):\n",
    "    angle = 0 #ball\n",
    "    return float(angle)\n",
    "  def angle3(self):\n",
    "    self.x1, self.y1 = self.array[23]\n",
    "    self.x2, self.y2 = self.array[25]\n",
    "    self.x3, self.y3 = self.array[27]\n",
    "    \n",
    "    try:\n",
    "      a1 = (self.y2 - self.y1) / (self.x2 - self.x1)\n",
    "    except ZeroDivisionError:\n",
    "      a1 = (self.y2 - self.y1) / 1\n",
    "    try: \n",
    "      a2 = (self.y3 - self.y2) / (self.x3 - self.x2)\n",
    "    except ZeroDivisionError:\n",
    "      a2 = (self.y3 - self.y2) / 1\n",
    "    \n",
    "    angle_rad = math.atan(abs((a1 - a2) / (1 + a1 * a2)))\n",
    "    angle = math.degrees(angle_rad)\n",
    "    return angle\n",
    "  def angle4(self):\n",
    "    self.x1, self.y1 = self.array[25]\n",
    "    self.x2, self.y2 = self.array[27]\n",
    "    self.x3, self.y3 = self.array[31]\n",
    "    \n",
    "    try:\n",
    "      a1 = (self.y2 - self.y1) / (self.x2 - self.x1)\n",
    "    except ZeroDivisionError:\n",
    "      a1 = (self.y2 - self.y1) / 1\n",
    "    try: \n",
    "      a2 = (self.y3 - self.y2) / (self.x3 - self.x2)\n",
    "    except ZeroDivisionError:\n",
    "      a2 = (self.y3 - self.y2) / 1\n",
    "    \n",
    "    angle_rad = math.atan(abs((a1 - a2) / (1 + a1 * a2)))\n",
    "    angle = math.degrees(angle_rad)\n",
    "    return 180 - angle\n",
    "  def angle5(self):\n",
    "    self.x1, self.y1 = self.array[26]\n",
    "    self.x2, self.y2 = self.array[30]\n",
    "    self.x3, self.y3 = [self.array[26][0],self.array[30][1]]\n",
    "    \n",
    "    try:\n",
    "      a1 = (self.y2 - self.y1) / (self.x2 - self.x1)\n",
    "    except ZeroDivisionError:\n",
    "      a1 = (self.y2 - self.y1) / 1\n",
    "    try: \n",
    "      a2 = (self.y3 - self.y2) / (self.x3 - self.x2)\n",
    "    except ZeroDivisionError:\n",
    "      a2 = (self.y3 - self.y2) / 1\n",
    "    \n",
    "    angle_rad = math.atan(abs((a1 - a2) / (1 + a1 * a2)))\n",
    "    angle = math.degrees(angle_rad)\n",
    "    return angle\n",
    "  def angle6(self):\n",
    "    self.x1, self.y1 = self.array[12]\n",
    "    self.x2, self.y2 = self.array[24]\n",
    "    self.x3, self.y3 = [self.array[12][0],self.array[24][1]]\n",
    "    \n",
    "    try:\n",
    "      a1 = (self.y2 - self.y1) / (self.x2 - self.x1)\n",
    "    except ZeroDivisionError:\n",
    "      a1 = (self.y2 - self.y1) / 1\n",
    "    try:\n",
    "      a2 = (self.y3 - self.y2) / (self.x3 - self.x2)\n",
    "    except ZeroDivisionError:\n",
    "      a2 = (self.y3 - self.y2) / 1\n",
    "    \n",
    "    angle_rad = math.atan(abs((a1 - a2) / (1 + a1 * a2)))\n",
    "    angle = math.degrees(angle_rad)\n",
    "    return angle\n",
    "  def values(self):\n",
    "    a1 = self.angle1()\n",
    "    a2 = self.angle2()\n",
    "    a3 = self.angle3()\n",
    "    a4 = self.angle4()\n",
    "    a5 = self.angle5()\n",
    "    a6 = self.angle6()\n",
    "    ary = []\n",
    "    ary.append(a1)\n",
    "    ary.append(a2)\n",
    "    ary.append(a3)\n",
    "    ary.append(a4)\n",
    "    ary.append(a5)\n",
    "    ary.append(a6)\n",
    "    return ary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 데이터를 가지고 오기 * data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pj_path = 'mp'\n",
    "save_PATH = os.path.join('result')\n",
    "dataset = glob('data/test/O/*')+ glob('data/train/O/*') + glob('data/valid/O/*')\n",
    "#print(dataset)\n",
    "image_li = []\n",
    "for data in dataset:\n",
    "  #img = cv2.GaussianBlur(raw_img, (11, 11), 0)  # blur\n",
    "  img = cv2.imread(data)\n",
    "  #define param :) contrast = 0~127, brightness : 0~100\n",
    "  contrast =0.8\n",
    "  brightness = 1\n",
    "  img = cv2.convertScaleAbs(img, alpha= contrast, beta = brightness)\n",
    "  \n",
    "  #img = cv2.equalizeHist(img, dst=None)\n",
    "  h, w, _ = img.shape\n",
    "  #img = center_crop(img, 800)\n",
    "  image_li.append(img)\n",
    "  \n",
    "print(image_li[0].shape)\n",
    "print(len(image_li))\n",
    "#plt.imshow(image_li[0])\n",
    "\n",
    "i=1\n",
    "for img in image_li:\n",
    "  plt.imshow(img)\n",
    "  break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pose detect with mediapipe API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### detect pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf result/{test,train,valid}/{O,X}/{mask,pose}/*\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "pj_path = 'mp'\n",
    "save_PATH = os.path.join('result')\n",
    "#data_class = ['valid']\n",
    "data_class = ['train', 'valid', 'test']\n",
    "classes = ['O', 'X']\n",
    "\n",
    "dataset = glob(f'data/*/*/*')\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode = True,\n",
    "    model_complexity = 2,\n",
    "    enable_segmentation=True,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    ") as pose:\n",
    "    image_li = []\n",
    "    df = pd.DataFrame()\n",
    "    contrast = 0.7\n",
    "    brightness = 1.5\n",
    "    for data in dataset:\n",
    "        image = cv2.imread(data)\n",
    "        image_li.append(image)\n",
    "        image = cv2.convertScaleAbs(image, alpha = contrast, beta = brightness)\n",
    "        h, w, _ = image.shape\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        condition = np.stack((results.segmentation_mask, ) * 3, axis = -1) > 0.1 \n",
    "        bg_image = np.zeros(image.shape, dtype = np.uint8)\n",
    "        bg_image[:] = (192,192,192)\n",
    "        annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "        x = []\n",
    "        image.flags.writeable = False\n",
    "        for k in range(33):\n",
    "            #print(data)\n",
    "            for k in range(33):\n",
    "                if results.pose_landmarks:\n",
    "                    x.append(results.pose_landmarks.landmark[k].x)\n",
    "                    x.append(results.pose_landmarks.landmark[k].y)\n",
    "                    x.append(results.pose_landmarks.landmark[k].z)\n",
    "                    x.append(results.pose_landmarks.landmark[k].visibility)\n",
    "            \n",
    "            # list x를 dataframe으로 변경\n",
    "            tmp = pd.DataFrame(x)\n",
    "            # dataframe에 정보 쌓아주기\n",
    "            # 33개 landmarks의 132개 정보가 dataframe에 담긴다.\n",
    "            df = pd.concat([df, tmp])\n",
    "            \n",
    "            #이미지 위에 pose landmark 그리기  \n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "            image_path = f'result/t/t/pose/' + str(data.split('/')[-1])\n",
    "            cv2.imwrite(image_path, image)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "            anno_image_path = f'result/t/t/mask/' + str(data.split('/')[-1])\n",
    "            #print(anno_image_path)\n",
    "            cv2.imwrite(anno_image_path, annotated_image)\n",
    "                \n",
    "            #data angle cal\n",
    "        if not results.pose_landmarks:\n",
    "                continue\n",
    "        res = results.pose_landmarks\n",
    "        land_list = [[landmark.x, landmark.y]for landmark in res.landmark]\n",
    "        land_dict = {}\n",
    "        for idx in range(len(image_li)):\n",
    "            width, height, _ = image_li[idx].shape\n",
    "            scaled_list = []\n",
    "            filename = str(dataset[idx])\n",
    "            land_dict[filename] = []\n",
    "            for x, y in land_list:\n",
    "                x = round(x * width)\n",
    "                y = round(y * height)\n",
    "                land_dict[filename].append([x,y])\n",
    "\n",
    "        save_df = pd.DataFrame(columns=['filepath', 'std1','std2','std3','std4','std5','std6'])\n",
    "        for key, val in land_dict.items():\n",
    "            cal = calculator(val, width = width, height = height)\n",
    "            angle = cal.values()\n",
    "            #print(angle)\n",
    "            save_df = save_df.append(\n",
    "                pd.DataFrame([[key, angle[0], angle[1], angle[2], angle[3], angle[4], angle[5]]],\n",
    "                                columns=['filepath','std1','std2','std3','std4','std5','std6']),\n",
    "                ignore_index=True)\n",
    "        print(f\"data name : t/t, len : {len(dataset)}\")\n",
    "        print(tabulate(save_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "        save_df.to_csv(f\"./result/csv/t_O_pose_data.csv\", mode='w')  \n",
    "\n",
    "### warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./result/csv/t_total_pose_data.csv').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./result/csv/t_O_pose_data.csv').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf result/{test,train,valid}/{O,X}/{mask,pose}/*\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "pj_path = 'mp'\n",
    "save_PATH = os.path.join('result')\n",
    "#data_class = ['valid']\n",
    "data_class = ['train', 'valid', 'test']\n",
    "classes = ['O', 'X']\n",
    "\n",
    "dataset_li = glob(f'data/*/*/*')\n",
    "print(dataset_li)\n",
    "break\n",
    "print(data_class)\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode = True,\n",
    "    model_complexity = 2,\n",
    "    enable_segmentation=True,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    ") as pose:\n",
    "    for datatype in data_class:\n",
    "        for class_one in classes:\n",
    "            image_li = []\n",
    "            df = pd.DataFrame()\n",
    "            dataset = dataset_li\n",
    "            #print(dataset)\n",
    "            #print(dataset)\n",
    "            ###########setting############\n",
    "            contrast =0.7\n",
    "            brightness = 1.5\n",
    "            for data in dataset:\n",
    "                #배경 제거\n",
    "                #print(data)\n",
    "                image = cv2.imread(data)\n",
    "                image_li.append(image)\n",
    "                ## 대조 밝기 변경 : 특정 데이터들떄문\n",
    "                image = cv2.convertScaleAbs(image, alpha = contrast, beta = brightness)\n",
    "                #print(image)\n",
    "                h, w, _ = image.shape\n",
    "                #print(h, w, _)\n",
    "                results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                #없어도해\n",
    "                if not results.pose_landmarks:\n",
    "                   continue\n",
    "                annotated_image = image.copy()\n",
    "                #사람만 추출\n",
    "                ### 공동 양방향 필터사용 * https://learn.foundry.com/ko/nuke/content/comp_environment/filters/bilateral.html\n",
    "                \n",
    "                condition = np.stack((results.segmentation_mask,) * 3, axis = -1) >0.1\n",
    "                \n",
    "                bg_image = np.zeros(image.shape, dtype = np.uint8)\n",
    "                bg_image[:] = (192,192,192) #배경 회색으로 처리       \n",
    "                annotated_image = np.where(condition, annotated_image, bg_image)\n",
    "                x = []\n",
    "                image.flags.writeable = False\n",
    "                #print(data)\n",
    "                for k in range(33):\n",
    "                    if results.pose_landmarks:\n",
    "                        x.append(results.pose_landmarks.landmark[k].x)\n",
    "                        x.append(results.pose_landmarks.landmark[k].y)\n",
    "                        x.append(results.pose_landmarks.landmark[k].z)\n",
    "                        x.append(results.pose_landmarks.landmark[k].visibility)\n",
    "                \n",
    "                # list x를 dataframe으로 변경\n",
    "                tmp = pd.DataFrame(x)\n",
    "                # dataframe에 정보 쌓아주기\n",
    "                # 33개 landmarks의 132개 정보가 dataframe에 담긴다.\n",
    "                df = pd.concat([df, tmp])\n",
    "                \n",
    "                #이미지 위에 pose landmark 그리기  \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                )\n",
    "                image_path = f'result/{datatype}/{class_one}/pose/' + str(data.split('/')[-1])\n",
    "                cv2.imwrite(image_path, image)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                )\n",
    "                anno_image_path = f'result/{datatype}/{class_one}/mask/' + str(data.split('/')[-1])\n",
    "                #print(anno_image_path)\n",
    "                cv2.imwrite(anno_image_path, annotated_image)\n",
    "                \n",
    "            #data angle cal\n",
    "            if not results.pose_landmarks:\n",
    "                    continue\n",
    "            res = results.pose_landmarks\n",
    "            land_list = [[landmark.x, landmark.y]for landmark in res.landmark]\n",
    "            land_dict = {}\n",
    "            for idx in range(len(image_li)):\n",
    "                width, height, _ = image_li[idx].shape\n",
    "                scaled_list = []\n",
    "                filename = str(dataset[idx])\n",
    "                land_dict[filename] = []\n",
    "                for x, y in land_list:\n",
    "                    x = round(x * width)\n",
    "                    y = round(y * height)\n",
    "                    land_dict[filename].append([x,y])\n",
    "\n",
    "            save_df = pd.DataFrame(columns=['filepath', 'std1','std2','std3','std4','std5','std6'])\n",
    "            for key, val in land_dict.items():\n",
    "                cal = calculator(val, width = width, height = height)\n",
    "                angle = cal.values()\n",
    "                #print(angle)\n",
    "                save_df = save_df.append(\n",
    "                    pd.DataFrame([[key, angle[0], angle[1], angle[2], angle[3], angle[4], angle[5]]],\n",
    "                                columns=['filepath','std1','std2','std3','std4','std5','std6']),\n",
    "                    ignore_index=True)\n",
    "            print(f\"data name : {datatype}/{class_one}, len : {len(dataset)}\")\n",
    "            print(tabulate(save_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "            save_df.to_csv(f\"./result/csv/{datatype}_{class_one}_pose_data.csv\", mode='w')  \n",
    "\n",
    "### warning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5가지 기준 각도 계산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원하게 가공"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O/X 기준에 따라 5가지 기준이 차이가 있는지 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data 가지고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./result/csv/total_X_pose_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제일잘한걸 ground truth로 할거\n",
    "gt_df = pd.concat([\n",
    "  #pd.read_csv('./result/csv/train_O_pose_data.csv').loc[{1,3}],  #2,13\n",
    "  #pd.read_csv('./result/csv/valid_O_pose_data.csv').loc[{1,3}], #1, 11\n",
    "  #pd.read_csv('./result/csv/valid_O_pose_data.csv').loc[{1,3}], #1, 11\n",
    "  pd.read_csv('./result/csv/t_t_pose_data.csv'), #1, 11\n",
    "  \n",
    "  #pd.read_csv('./result/csv/train_X_pose_data.csv'), #1, 11\n",
    "  #pd.read_csv('./result/csv/test_X_pose_data.csv'), #1, 11\n",
    "  ]\n",
    ")\n",
    "ff_df = pd.concat([\n",
    "  pd.read_csv('./result/csv/total_X_pose_data.csv'),\n",
    "  ])\n",
    "#ff에는 train모든 것들 다들어감 \n",
    "train_df = pd.concat([\n",
    "  pd.read_csv('./result/csv/train_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/train_X_pose_data.csv'),\n",
    "  ])\n",
    "\n",
    "#test \n",
    "test_df = pd.concat([\n",
    "  pd.read_csv('./result/csv/test_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/test_X_pose_data.csv'),\n",
    "  ])\n",
    "valid_df = pd.concat([\n",
    "  pd.read_csv('./result/csv/valid_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/valid_X_pose_data.csv'),\n",
    "])\n",
    "\n",
    "O_df = pd.concat([\n",
    "  pd.read_csv('./result//csv/train_O_pose_data.csv'),\n",
    "  pd.read_csv('./result//csv/valid_O_pose_data.csv'),\n",
    "  pd.read_csv('./result//csv/test_O_pose_data.csv'),\n",
    "])\n",
    "\n",
    "X_df = pd.concat([\n",
    "  pd.read_csv('./result//csv/train_X_pose_data.csv'),\n",
    "  pd.read_csv('./result//csv/valid_X_pose_data.csv'),\n",
    "])\n",
    "\n",
    "total_df = pd.concat([\n",
    "  pd.read_csv('./result/csv/t_total_pose_data.csv'),\n",
    "\n",
    "])\n",
    "gt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_676421/1119278492.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  gt_df.mean() #std4: 20,std5 : 5, std6 : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      5.500000\n",
       "std1          127.665781\n",
       "std2            0.000000\n",
       "std3           24.302876\n",
       "std4          170.510860\n",
       "std5           82.943748\n",
       "std6           82.179712\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.mean() #std4: 20,std5 : 5, std6 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계 분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heatmapd 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.iloc[0:]\n",
    "heatmap_df = gt_df[['std1','std2','std3','std4','std5','std6']]\n",
    "sns.heatmap(heatmap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_df.iloc[0:]\n",
    "ff_heatmap_df = ff_df[['std1','std2','std3','std4','std5','std6']]\n",
    "sns.heatmap(ff_heatmap_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### displot 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gt_df['std1'], color ='blue', label = 'O')\n",
    "sns.distplot(ff_df['std1'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "#plt.savefig('./result/plot/scoring_std1.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(gt_df['std3'], color ='blue', label = 'O')\n",
    "sns.distplot(ff_df['std3'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "#plt.savefig('./result/plot/scoring_std3.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(gt_df['std4'], color ='blue', label = 'O')\n",
    "sns.distplot(ff_df['std4'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "#plt.savefig('./result/plot/std4.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(gt_df['std5'], color ='blue', label = 'O')\n",
    "sns.distplot(ff_df['std5'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "#plt.savefig('./result/plot/std5.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(gt_df['std6'], color ='blue', label = 'O')\n",
    "sns.distplot(ff_df['std6'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "#plt.savefig('./result/plot/std6.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### boxplot 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기준별 개인 점수화 계산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feedback code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std1</th>\n",
       "      <th>std3</th>\n",
       "      <th>std4</th>\n",
       "      <th>std5</th>\n",
       "      <th>std6</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/train/X/X_img_8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/train/X/X_img_58.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/train/X/X_img_34.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/train/X/X_img_62.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>correct</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/train/X/X_img_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/train/X/X_img_35.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/train/X/X_img_54.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/train/X/X_img_31.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/train/X/X_img_61.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/train/X/X_img_56.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/O/O_img_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/O/O_img_13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/O/O_img_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/O/O_img_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_16.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_21.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_33.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_26.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>correct</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/valid/X/X_img_60.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>correct</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_48.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_32.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/valid/X/X_img_57.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>data/valid/X/X_img_52.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>Increase the angle of reference.</td>\n",
       "      <td>correct</td>\n",
       "      <td>correct</td>\n",
       "      <td>Reduce the angle of reference.</td>\n",
       "      <td>data/valid/X/X_img_43.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                std1                              std3  \\\n",
       "43  Increase the angle of reference.  Increase the angle of reference.   \n",
       "44                           correct                           correct   \n",
       "45  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "46                           correct                           correct   \n",
       "47                           correct  Increase the angle of reference.   \n",
       "48  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "49                           correct                           correct   \n",
       "50  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "51                           correct                           correct   \n",
       "52                           correct                           correct   \n",
       "53  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "54    Reduce the angle of reference.    Reduce the angle of reference.   \n",
       "55  Increase the angle of reference.  Increase the angle of reference.   \n",
       "56  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "57  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "58  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "59  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "60  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "61  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "62  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "63  Increase the angle of reference.  Increase the angle of reference.   \n",
       "64                           correct  Increase the angle of reference.   \n",
       "65                           correct                           correct   \n",
       "66  Increase the angle of reference.  Increase the angle of reference.   \n",
       "67                           correct  Increase the angle of reference.   \n",
       "68    Reduce the angle of reference.  Increase the angle of reference.   \n",
       "69  Increase the angle of reference.    Reduce the angle of reference.   \n",
       "70                           correct                           correct   \n",
       "71                           correct                           correct   \n",
       "72    Reduce the angle of reference.  Increase the angle of reference.   \n",
       "\n",
       "       std4     std5                            std6  \\\n",
       "43  correct  correct  Reduce the angle of reference.   \n",
       "44  correct  correct                         correct   \n",
       "45  correct  correct  Reduce the angle of reference.   \n",
       "46  correct  correct                         correct   \n",
       "47  correct  correct  Reduce the angle of reference.   \n",
       "48  correct  correct  Reduce the angle of reference.   \n",
       "49  correct  correct                         correct   \n",
       "50  correct  correct  Reduce the angle of reference.   \n",
       "51  correct  correct                         correct   \n",
       "52  correct  correct                         correct   \n",
       "53  correct  correct  Reduce the angle of reference.   \n",
       "54  correct  correct  Reduce the angle of reference.   \n",
       "55  correct  correct  Reduce the angle of reference.   \n",
       "56  correct  correct  Reduce the angle of reference.   \n",
       "57  correct  correct  Reduce the angle of reference.   \n",
       "58  correct  correct  Reduce the angle of reference.   \n",
       "59  correct  correct  Reduce the angle of reference.   \n",
       "60  correct  correct  Reduce the angle of reference.   \n",
       "61  correct  correct  Reduce the angle of reference.   \n",
       "62  correct  correct  Reduce the angle of reference.   \n",
       "63  correct  correct  Reduce the angle of reference.   \n",
       "64  correct  correct  Reduce the angle of reference.   \n",
       "65  correct  correct                         correct   \n",
       "66  correct  correct  Reduce the angle of reference.   \n",
       "67  correct  correct  Reduce the angle of reference.   \n",
       "68  correct  correct  Reduce the angle of reference.   \n",
       "69  correct  correct  Reduce the angle of reference.   \n",
       "70  correct  correct                         correct   \n",
       "71  correct  correct                         correct   \n",
       "72  correct  correct  Reduce the angle of reference.   \n",
       "\n",
       "                     filepath  \n",
       "43   data/train/X/X_img_8.jpg  \n",
       "44  data/train/X/X_img_58.jpg  \n",
       "45  data/train/X/X_img_34.jpg  \n",
       "46  data/train/X/X_img_62.jpg  \n",
       "47   data/train/X/X_img_3.jpg  \n",
       "48  data/train/X/X_img_35.jpg  \n",
       "49  data/train/X/X_img_54.jpg  \n",
       "50  data/train/X/X_img_31.jpg  \n",
       "51  data/train/X/X_img_61.jpg  \n",
       "52  data/train/X/X_img_56.jpg  \n",
       "53   data/valid/O/O_img_4.jpg  \n",
       "54  data/valid/O/O_img_13.jpg  \n",
       "55  data/valid/O/O_img_10.jpg  \n",
       "56   data/valid/O/O_img_5.jpg  \n",
       "57  data/valid/X/X_img_16.jpg  \n",
       "58  data/valid/X/X_img_21.jpg  \n",
       "59  data/valid/X/X_img_33.jpg  \n",
       "60  data/valid/X/X_img_26.jpg  \n",
       "61  data/valid/X/X_img_24.jpg  \n",
       "62   data/valid/X/X_img_4.jpg  \n",
       "63   data/valid/X/X_img_2.jpg  \n",
       "64  data/valid/X/X_img_10.jpg  \n",
       "65  data/valid/X/X_img_60.jpg  \n",
       "66  data/valid/X/X_img_13.jpg  \n",
       "67  data/valid/X/X_img_11.jpg  \n",
       "68  data/valid/X/X_img_48.jpg  \n",
       "69  data/valid/X/X_img_32.jpg  \n",
       "70  data/valid/X/X_img_57.jpg  \n",
       "71  data/valid/X/X_img_52.jpg  \n",
       "72  data/valid/X/X_img_43.jpg  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt_df = pd.read_csv('./data/pose_data/O_pose_data.csv')\n",
    "#gt_df.insert(9, 'label', 1.0)\n",
    "std_df = ff_df.iloc[:,2:]\n",
    "filepath_df = total_df.iloc[:,1] #파일명만 따로가지고옴\n",
    "std_dict = { \n",
    "            'std1' : std_df['std1'].mean(),\n",
    "            #'std2' : std_df['std2'].mean(),\n",
    "            'std3' : std_df['std3'].mean(),\n",
    "            'std4' : std_df['std4'].mean(),\n",
    "            'std5' : std_df['std5'].mean(),\n",
    "            'std6' : std_df['std6'].mean(),\n",
    "}\n",
    "\n",
    "\n",
    "#### 평균각도와 인풋각도간의 차이를 구하고 피드백하는 코드\n",
    "test_std_dict = {\n",
    "            'std1' : list(total_df['std1'].values),\n",
    "            #'std2' : list(total_df['std2'].values),\n",
    "            'std3' : list(total_df['std3'].values),\n",
    "            'std4' : list(total_df['std4'].values),\n",
    "            'std5' : list(total_df['std5'].values),\n",
    "            'std6' : list(total_df['std6'].values),\n",
    "}\n",
    "\n",
    "filepath_df = total_df.iloc[:,1] #파일명만 따로가지고옴\n",
    "score_dict=dict()\n",
    "\n",
    "#피드백주기\n",
    "bandwidth = 10\n",
    "for key, values in test_std_dict.items():\n",
    "  std = std_dict[key]\n",
    "  score_li = []\n",
    "  for i in range(len(values)):\n",
    "    score = std - values[i]\n",
    "    #피드백 주는 코드공간\n",
    "    if abs(score) >= bandwidth:\n",
    "      score = 'correct' # 잘했으면 피드백으로는 잘차고 있다고 피드백 \n",
    "    elif (score > 0)and(score < bandwidth):\n",
    "      score = 'Reduce the angle of reference.' #기준각보다 벌려져있다면\n",
    "    elif (score < 0) and( score > -bandwidth):  \n",
    "      score = 'Increase the angle of reference.' #기준각보다 좁다면\n",
    "      \n",
    "    score_li.append(score)\n",
    "  score_dict[key] = score_li\n",
    "  \n",
    "#for key, values in score_dict.items():\n",
    "#  print(\"첫번쨰 데이터만 확인하기\")\n",
    "#  print(f\"{filepath_df.values[0]} : {score_dict[key][0]}\")\n",
    "\n",
    "X_p_score = pd.DataFrame(score_dict)\n",
    "X_p_score= X_p_score.reset_index()\n",
    "filepath_df = filepath_df.reset_index()\n",
    "result = pd.concat([X_p_score.iloc[:,1:], filepath_df.iloc[:,-1]], axis = 1)\n",
    "result.tail(30)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/valid set 점수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############train######################\n",
    "#train_df = pd.read_csv('./data/pose_data/O_pose_data.csv')\n",
    "#train_df.insert(9, 'label', 1.0)\n",
    "X_df = train_df.iloc[:,2:]\n",
    "filepath_df = train_df.iloc[:,1] #파일명만 따로가지고옴\n",
    "\n",
    "X_test_std_dict = {\n",
    "            'std1' : list(X_df['std1'].values),\n",
    "            #'std2' : list(X_df['std2'].values),\n",
    "            'std3' : list(X_df['std3'].values),\n",
    "            'std4' : list(X_df['std4'].values),\n",
    "            'std5' : list(X_df['std5'].values),\n",
    "            'std6' : list(X_df['std6'].values),\n",
    "}\n",
    "X_test_std_dict\n",
    "score_dict = dict()\n",
    "\n",
    "print(len(X_test_std_dict.items()))\n",
    "\n",
    "\n",
    "#점수화시키기\n",
    "for key, values in X_test_std_dict.items():\n",
    "  #print(len(values))\n",
    "  std = std_dict[key]\n",
    "  #print(std)\n",
    "  score_li = []\n",
    "  for i in range(len(values)):\n",
    "    score = (1-(abs(values[i]- std)/std)) * 100\n",
    "    score_li.append(score)\n",
    "  score_dict[key] = score_li\n",
    "print(len(score_dict['std1'])) \n",
    "  \n",
    "#for key, values in score_dict.items():\n",
    "#  print(\"첫번쨰 데이터만 확인하기\")\n",
    "#  print(f\"{filepath_df.values[0]} : {score_dict[key][0]}\")\n",
    "\n",
    "X_p_score = pd.DataFrame(score_dict)\n",
    "X_p_score= X_p_score.reset_index()\n",
    "filepath_df = filepath_df.reset_index()\n",
    "\n",
    "result = pd.concat([X_p_score.iloc[:,1:], filepath_df.iloc[:,-1]], axis = 1)\n",
    "result.to_csv('./result/std_scoring_csv/train_scoring.csv')\n",
    "result\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_gt_df = pd.read_csv('./result/std_scoring_csv/train_scoring.csv')\n",
    "O_df = score_gt_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in O_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "O_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "O_total_df\n",
    "total_O_df = pd.concat([score_gt_df, O_total_df],axis=1)\n",
    "\n",
    "total_O_df\n",
    "print(tabulate(total_O_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_train_df = pd.read_csv('./result/std_scoring_csv/train_scoring.csv')\n",
    "X_df = score_train_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in X_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "X_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "X_total_df\n",
    "total_X_df = pd.concat([score_train_df, X_total_df],axis=1)\n",
    "total_X_df.to_csv('./result/std_scoring_csv/total_train_scoring.csv')\n",
    "\n",
    "print(tabulate(total_X_df, headers='keys', tablefmt='psql', showindex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############train######################\n",
    "#ff_df = pd.read_csv('./data/pose_data/O_pose_data.csv')\n",
    "#ff_df.insert(9, 'label', 1.0)\n",
    "X_df = valid_df.iloc[:,2:]\n",
    "filepath_df = valid_df.iloc[:,1] #파일명만 따로가지고옴\n",
    "\n",
    "X_test_std_dict = {\n",
    "            'std1' : list(X_df['std1'].values),\n",
    "            #'std2' : list(X_df['std2'].values),\n",
    "            'std3' : list(X_df['std3'].values),\n",
    "            'std4' : list(X_df['std4'].values),\n",
    "            'std5' : list(X_df['std5'].values),\n",
    "            'std6' : list(X_df['std6'].values),\n",
    "}\n",
    "X_test_std_dict\n",
    "score_dict = dict()\n",
    "\n",
    "print(len(X_test_std_dict.items()))\n",
    "\n",
    "\n",
    "#점수화시키기\n",
    "for key, values in X_test_std_dict.items():\n",
    "  #print(len(values))\n",
    "  std = std_dict[key]\n",
    "  #print(std)\n",
    "  score_li = []\n",
    "  for i in range(len(values)):\n",
    "    score = (1-(abs(values[i]- std)/std)) * 100\n",
    "    score_li.append(score)\n",
    "  score_dict[key] = score_li\n",
    "print(len(score_dict['std1'])) \n",
    "  \n",
    "#for key, values in score_dict.items():\n",
    "#  print(\"첫번쨰 데이터만 확인하기\")\n",
    "#  print(f\"{filepath_df.values[0]} : {score_dict[key][0]}\")\n",
    "\n",
    "X_p_score = pd.DataFrame(score_dict)\n",
    "X_p_score= X_p_score.reset_index()\n",
    "filepath_df = filepath_df.reset_index()\n",
    "\n",
    "result = pd.concat([X_p_score.iloc[:,1:], filepath_df.iloc[:,-1]], axis = 1)\n",
    "result.to_csv('./result/std_scoring_csv/valid_scoring.csv')\n",
    "result\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_gt_df = pd.read_csv('./result/std_scoring_csv/valid_scoring.csv')\n",
    "O_df = score_gt_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in O_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "O_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "O_total_df\n",
    "total_O_df = pd.concat([score_gt_df, O_total_df],axis=1)\n",
    "\n",
    "total_O_df\n",
    "print(tabulate(total_O_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_ff_df = pd.read_csv('./result/std_scoring_csv/valid_scoring.csv')\n",
    "X_df = score_ff_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in X_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "X_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "X_total_df\n",
    "total_X_df = pd.concat([score_ff_df, X_total_df],axis=1)\n",
    "total_X_df.to_csv('./result/std_scoring_csv/total_valid_scoring.csv')\n",
    "\n",
    "print(tabulate(total_X_df, headers='keys', tablefmt='psql', showindex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############test######################\n",
    "#test_df = pd.read_csv('./data/pose_data/O_pose_data.csv')\n",
    "#test_df.insert(9, 'label', 1.0)\n",
    "X_df = test_df.iloc[:,2:]\n",
    "filepath_df = test_df.iloc[:,1] #파일명만 따로가지고옴\n",
    "\n",
    "X_test_std_dict = {\n",
    "            'std1' : list(X_df['std1'].values),\n",
    "            #'std2' : list(X_df['std2'].values),\n",
    "            'std3' : list(X_df['std3'].values),\n",
    "            'std4' : list(X_df['std4'].values),\n",
    "            'std5' : list(X_df['std5'].values),\n",
    "            'std6' : list(X_df['std6'].values),\n",
    "}\n",
    "X_test_std_dict\n",
    "score_dict = dict()\n",
    "\n",
    "print(len(X_test_std_dict.items()))\n",
    "\n",
    "\n",
    "#점수화시키기\n",
    "for key, values in X_test_std_dict.items():\n",
    "  #print(len(values))\n",
    "  std = std_dict[key]\n",
    "  #print(std)\n",
    "  score_li = []\n",
    "  for i in range(len(values)):\n",
    "    score = (1-(abs(values[i]- std)/std)) * 100\n",
    "    score_li.append(score)\n",
    "  score_dict[key] = score_li\n",
    "print(len(score_dict['std1'])) \n",
    "  \n",
    "#for key, values in score_dict.items():\n",
    "#  print(\"첫번쨰 데이터만 확인하기\")\n",
    "#  print(f\"{filepath_df.values[0]} : {score_dict[key][0]}\")\n",
    "\n",
    "X_p_score = pd.DataFrame(score_dict)\n",
    "X_p_score= X_p_score.reset_index()\n",
    "filepath_df = filepath_df.reset_index()\n",
    "\n",
    "result = pd.concat([X_p_score.iloc[:,1:], filepath_df.iloc[:,-1]], axis = 1)\n",
    "result.to_csv('./result/std_scoring_csv/test_scoring.csv')\n",
    "result\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_gt_df = pd.read_csv('./result/std_scoring_csv/test_scoring.csv')\n",
    "O_df = score_gt_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in O_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "O_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "O_total_df\n",
    "total_O_df = pd.concat([score_gt_df, O_total_df],axis=1)\n",
    "\n",
    "total_O_df\n",
    "print(tabulate(total_O_df, headers='keys', tablefmt='psql', showindex=True))\n",
    "\n",
    "#각 std별 개인별점수\n",
    "score_test_df = pd.read_csv('./result/std_scoring_csv/test_scoring.csv')\n",
    "X_df = score_test_df.iloc[:,:]\n",
    "#score sum : std1_score + std2_score + std4_score + std5_score + std6_score \n",
    "total_score_append = list()\n",
    "for index,row in X_df.iterrows():\n",
    "  total_score = (row['std1'] + row['std3']+ row['std4']+ row['std5']+ row['std6']) /5\n",
    "  total_score_append.append(total_score)\n",
    "    \n",
    "X_total_df = pd.DataFrame({'total_score': total_score_append})\n",
    "X_total_df\n",
    "total_X_df = pd.concat([score_test_df, X_total_df],axis=1)\n",
    "total_X_df.to_csv('./result/std_scoring_csv/total_test_scoring.csv')\n",
    "\n",
    "print(tabulate(total_X_df, headers='keys', tablefmt='psql', showindex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_O_df = pd.read_csv('./result/csv/total_O_pose_data.csv')\n",
    "heatmap_df = total_O_df[['std1','std3','std4','std5','std6']]\n",
    "sns.heatmap(heatmap_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_X_df = pd.read_csv('./result/csv/total_X_pose_data.csv')\n",
    "heatmap_df = total_X_df[['std1','std3','std4','std5','std6']]\n",
    "sns.heatmap(heatmap_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O 기준 점수 내기 플랏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gt_df = pd.read_csv('./result/std_scoring_csv/std_O_scoring.csv')\n",
    "reg_ff_df = pd.read_csv('./result/std_scoring_csv/std_X_scoring.csv')\n",
    "\n",
    "sns.distplot(reg_gt_df['std1'], color ='blue', label = 'O')\n",
    "sns.distplot(reg_ff_df['std1'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "plt.savefig('./result/plot/scoring_std1.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(reg_gt_df['std3'], color ='blue', label = 'O')\n",
    "sns.distplot(reg_ff_df['std3'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "plt.savefig('./result/plot/scoring_std3.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(reg_gt_df['std4'], color ='blue', label = 'O')\n",
    "sns.distplot(reg_ff_df['std4'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "plt.savefig('./result/plot/scoring_std4.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(reg_gt_df['std5'], color ='blue', label = 'O')\n",
    "sns.distplot(reg_ff_df['std5'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "plt.savefig('./result/plot/scoring_std5.png')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(reg_gt_df['std6'], color ='blue', label = 'O')\n",
    "sns.distplot(reg_ff_df['std6'], color ='red', label = 'X')\n",
    "plt.legend(title='O/X')\n",
    "plt.savefig('./result/plot/scoring_std6.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gt_df.iloc[0:]\n",
    "heatmap_df = reg_gt_df[['std1','std3','std4','std5','std6']]\n",
    "sns.heatmap(heatmap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ff_df.iloc[0:]\n",
    "heatmap_df = reg_ff_df[['std1','std3','std4','std5','std6']]\n",
    "sns.heatmap(heatmap_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O 점수의 Total label table 만들기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O/X분류모델을 이용한 종합점수에 대한 상관관계 찾기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 윤주모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([\n",
    "  pd.read_csv('./result/csv/train_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/train_X_pose_data.csv'),\n",
    "])\n",
    "valid_data = pd.concat([\n",
    "  pd.read_csv('./result/csv/valid_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/valid_X_pose_data.csv'),\n",
    "])\n",
    "train_data['res'] = 0\n",
    "train_data['res'][0:5] = 100\n",
    "valid_data['res'] = 0\n",
    "valid_data['res'][0:4] = 100\n",
    "\n",
    "test_data = pd.concat([\n",
    "  pd.read_csv('./result/csv/test_O_pose_data.csv'),\n",
    "  pd.read_csv('./result/csv/test_X_pose_data.csv'),\n",
    "])\n",
    "test_data['res'] = 0\n",
    "test_data['res'][0:4] = 100\n",
    "\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터셋 클래스 정의\n",
    "class AngleDataset(Dataset):\n",
    "    def __init__(self, angles, labels):\n",
    "        self.angles = angles\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.angles)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        angle = self.angles[index]\n",
    "        label = self.labels[index]\n",
    "        return angle, label\n",
    "      \n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, angles, labels):\n",
    "        self.angles = angles\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.angles)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        angle = self.angles[index]\n",
    "        label = self.labels[index]\n",
    "        return angle, label\n",
    "    \n",
    "# MLP 모델 클래스 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.features.weight.data.uniform_ = (-0.5,0.5)\n",
    "        self.classifier.weight.data.uniform_ = (-0.5,0.5)\n",
    "        self.classifier.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0: 'O', 1: 'X'}\n",
    "\n",
    "train_angle1 = torch.tensor(train_data.iloc[:,2:3].to_numpy()).to(torch.float32)\n",
    "train_angle3 = torch.tensor(train_data.iloc[:,4:5].to_numpy()).to(torch.float32)\n",
    "train_angle4 = torch.tensor(train_data.iloc[:,5:6].to_numpy()).to(torch.float32)\n",
    "train_angle5 = torch.tensor(train_data.iloc[:,6:7].to_numpy()).to(torch.float32)\n",
    "train_angle6 = torch.tensor(train_data.iloc[:,7:8].to_numpy()).to(torch.float32)\n",
    "train_labels = torch.tensor(train_data.iloc[:,8:9].to_numpy()).to(torch.float32)\n",
    "\n",
    "valid_angle1 = torch.tensor(valid_data.iloc[:, 2:3].to_numpy()).to(torch.float32)\n",
    "valid_angle3 = torch.tensor(valid_data.iloc[:, 4:5].to_numpy()).to(torch.float32)\n",
    "valid_angle4 = torch.tensor(valid_data.iloc[:, 5:6].to_numpy()).to(torch.float32)\n",
    "valid_angle5 = torch.tensor(valid_data.iloc[:, 6:7].to_numpy()).to(torch.float32)\n",
    "valid_angle6 = torch.tensor(valid_data.iloc[:, 7:8].to_numpy()).to(torch.float32)\n",
    "valid_labels = torch.tensor(valid_data.iloc[:, 8:9].to_numpy()).to(torch.float32)\n",
    "\n",
    "angles = [[angle1, angle3, angle4, angle5, angle6] for angle1, angle3, angle4, angle5, angle6 in zip(train_angle1, train_angle3, train_angle4, train_angle5, train_angle6)]\n",
    "labels = [class_mapping[int(label.item())] for label in train_labels]\n",
    "labels = [0 if label == 0 else 1 for label in train_labels]\n",
    "train_labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "valid_angles = [[angle1, angle3, angle4, angle5, angle6] for angle1, angle3, angle4, angle5, angle6 in zip(valid_angle1, valid_angle3, valid_angle4, valid_angle5, valid_angle6)]\n",
    "valid_labels = [class_mapping[int(label.item())] for label in valid_labels]\n",
    "valid_labels = [0 if label == 0 else 1 for label in valid_labels]\n",
    "valid_labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "angles = scaler.fit_transform(angles)\n",
    "\n",
    "valid_angles = torch.tensor(valid_angles, dtype=torch.float32)\n",
    "valid_angles = scaler.transform(valid_angles)\n",
    "\n",
    "#############dataset & dataloader\n",
    "batch_size = 10\n",
    "\n",
    "dataset = AngleDataset(angles, labels)\n",
    "valid_dataset = ValidationDataset(valid_angles, valid_labels)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size= batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(train_data.iloc[:,2:-2].to_numpy()).to(torch.float32)\n",
    "y = torch.tensor(train_data.iloc[:,-1].to_numpy()).to(torch.float32)\n",
    "X_vd = torch.tensor(valid_data.iloc[:,2:-2].to_numpy()).to(torch.float32)\n",
    "y_vd = torch.tensor(valid_data.iloc[:,-1].to_numpy()).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def data_iter(data, label, batch_size):\n",
    "  N,num_features = data.shape\n",
    "  inds = list(range(N))\n",
    "  random.shuffle(inds)\n",
    "  for i in range(0,N,batch_size):\n",
    "    batch_inds = inds[i:min(i+batch_size, N)]\n",
    "    batch_data = data[batch_inds,:]\n",
    "    batch_label = label[batch_inds]\n",
    "    yield batch_data, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 2000\n",
    "lr = 0.00042\n",
    "batch_size = 10\n",
    "# nonlinear activation을 포함하는 MLP model\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(5,400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400,1)\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss(reduction=\"mean\")\n",
    "alg = torch.optim.SGD(model2.parameters(),lr)\n",
    "\n",
    "# loop for learning\n",
    "loss_valid_epoch = []\n",
    "loss_valid_step = []\n",
    "\n",
    "for j in np.arange(0,num_epoch):\n",
    "  correct_score = 0\n",
    "  mydata_iter = data_iter(X,y,batch_size)\n",
    "  for batch_X,batch_y in mydata_iter:\n",
    "    y_hat = model2(batch_X)         # 1. forward\n",
    "    l = loss(y_hat, batch_y.reshape(y_hat.shape))    # 2. loss calculation\n",
    "    l.backward()                  # 3. backward\n",
    "    alg.step()                  # 4. parameter update\n",
    "    alg.zero_grad()               \n",
    "    loss_valid_step.append(l.detach())\n",
    "  \n",
    "  \n",
    "  y_vd_hat = model2(X_vd)  \n",
    "  l_all = loss(y_vd_hat,y_vd.reshape(y_vd_hat.shape))\n",
    "  loss_valid_epoch.append(l_all.detach())\n",
    "  for i in range(len(y_vd_hat.data)):\n",
    "    if y_vd_hat.data[i].item() >80:\n",
    "      y_vd_hat.data[i] = 100\n",
    "    else:\n",
    "      y_vd_hat.data[i] = 0\n",
    "  y_vd_hat = torch.squeeze(y_vd_hat, 1)\n",
    "  correct_score += (y_vd.data == y_vd_hat.data).sum().item()\n",
    "  \n",
    "  print(y_vd)\n",
    "  print(y_vd_hat)\n",
    "  print(correct_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_valid_epoch,':')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "#plt.axis([0,num_epoch,0,15])\n",
    "plt.show()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_vd,y_vd_hat.detach().numpy())\n",
    "#plt.plot(np.arange(0,2),np.arange(0,2),':')\n",
    "plt.xlabel('y_vd')\n",
    "plt.ylabel('y_vd_hat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "input_dim = 5\n",
    "hidden_dim = 100\n",
    "output_dim = 2\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay= 0.01)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "loss_train_epoch = []\n",
    "loss_train_step = []\n",
    "loss_valid_epoch = []\n",
    "loss_valid_step = []\n",
    "acc_valid_epoch =[]\n",
    "acc_valid_step =[]\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_input, batch_label in train_loader:\n",
    "        #print(batch_label)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward 패스\n",
    "        outputs = model(batch_input)\n",
    "        # print(outputs)\n",
    "        # print(batch_label)\n",
    "        loss = criterion(outputs, batch_label)\n",
    "        #print(outputs)\n",
    "        # Backward 패스 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train_step.append(loss)\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    \n",
    "    # 현재 에포크의 손실 출력\n",
    "    #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_valid_input, batch_valid_label in valid_loader:\n",
    "            total_valid = 0\n",
    "            correct_valid = 0    \n",
    "            #print(batch_valid_label)\n",
    "            ##print(batch_valid_label)\n",
    "            batch_valid_output = model(batch_valid_input)\n",
    "            #print(batch_valid_output)\n",
    "            # print(batch_valid_output)\n",
    "            # print(batch_valid_label)\n",
    "            batch_valid_loss = criterion(batch_valid_output, batch_valid_label)\n",
    "            #print(batch_valid_output)\n",
    "            #print(batch_valid_loss.item())\n",
    "            #다합하기 3번나오는거 해서 loss 평균구하기\n",
    "            valid_loss = batch_valid_loss.item()\n",
    "            valid_loss\n",
    "            #print(batch_valid_output)\n",
    "            #print(len(valid_loader))\n",
    "            #정확도 확인\n",
    "            #_, valid_predicted = torch.max(batch_valid_output.data, 1)\n",
    "            valid_predicted = torch.argmax(batch_valid_output.data, dim= 1)\n",
    "            #print(batch_valid_label)\n",
    "            #print(valid_predicted)\n",
    "            print(batch_valid_label)\n",
    "            print(valid_predicted)\n",
    "            total_valid += batch_valid_label.size(0)\n",
    "            correct_valid += (valid_predicted == batch_valid_label).sum().item()\n",
    "            print(correct_valid)\n",
    "            valid_accuracy = correct_valid / batch_size\n",
    "#            print(batch_valid_label)\n",
    "#            print(batch_valid_output)\n",
    "            loss_valid_step.append(valid_loss)\n",
    "            acc_valid_step.append(valid_accuracy)\n",
    "        #print(2)\n",
    "        y_vd_hat = model(batch_valid_input)\n",
    "        l_all = criterion( y_vd_hat, batch_valid_label,)\n",
    "        loss_valid_epoch.append(l_all.detach())        \n",
    "       #print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "        \n",
    "        \n",
    "\n",
    "torch.save(   \n",
    "    model.state_dict(), \"./model/MLP.pth\"\n",
    ")\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_valid_epoch,':')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.axis([0,num_epochs, 0, max(loss_valid_epoch)])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 훈련시키고 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_angle1 = torch.tensor(test_data.iloc[:,2:3].to_numpy()).to(torch.float32)\n",
    "test_angle3 = torch.tensor(test_data.iloc[:,4:5].to_numpy()).to(torch.float32)\n",
    "test_angle4 = torch.tensor(test_data.iloc[:,5:6].to_numpy()).to(torch.float32)\n",
    "test_angle5 = torch.tensor(test_data.iloc[:,6:7].to_numpy()).to(torch.float32)\n",
    "test_angle6 = torch.tensor(test_data.iloc[:,7:8].to_numpy()).to(torch.float32)\n",
    "test_labels = torch.tensor(test_data.iloc[:,8:9].to_numpy()).to(torch.float32)\n",
    "\n",
    "# 테스트 데이터 생성\n",
    "test_angles = [[angle1, angle3, angle4, angle5, angle6] for angle1, angle3, angle4, angle5, angle6 in zip(test_angle1, test_angle3, test_angle4, test_angle5, test_angle6)]\n",
    "\n",
    "# 데이터를 NumPy 배열로 변환\n",
    "test_angles = torch.tensor(test_angles, dtype=torch.float32)\n",
    "\n",
    "# 입력 데이터 정규화\n",
    "test_angles = scaler.transform(test_angles)\n",
    "\n",
    "# 모델 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(test_angles, dtype=torch.float32)\n",
    "    outputs = model(test_inputs)\n",
    "    predicted = torch.argmax(outputs.data, dim = 1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "predicted_labels_int = [[label.item()] for label in predicted]\n",
    "predicted_labels = [class_mapping[label.item()] for label in predicted]\n",
    "#print(predicted_labels_int)\n",
    "test_labels_int = [[int(label.item())] for label in test_labels]\n",
    "print(f\"원래 :{test_labels_int}\")\n",
    "print(f\"예측 :{predicted_labels_int}\")\n",
    "      \n",
    "#print(len(predicted_labels))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 실제 레이블과 예측 레이블을 numpy 배열로 변환\n",
    "true_labels = test_labels.numpy()\n",
    "predicted_labels = np.array(predicted_labels_int)\n",
    "\n",
    "# Confusion Matrix 생성\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# 클래스 레이블\n",
    "class_labels = list(class_mapping.values())\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=class_labels,\n",
    "       yticklabels=class_labels,\n",
    "       title='Confusion Matrix',\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "\n",
    "# 각 셀에 숫자 표시\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
